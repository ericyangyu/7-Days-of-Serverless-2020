{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "hw3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericyangyu/2020-25-Days-of-Serverless/blob/master/HW%203/hw3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnDi76EpOWet"
      },
      "source": [
        "# CSE 158 HW 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qei7_D0wOZsE",
        "outputId": "49d0a717-bba7-49d0-9296-26002a7942df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYs7ncHcOisH"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/CSE 158/HW 3/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VHMtoUWOykL",
        "outputId": "c68f9007-a8ce-46d1-eb85-63afad011e76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/gdrive/My Drive/CSE\\ 158/HW\\ 3/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/CSE 158/HW 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdS5ZmjcOWew"
      },
      "source": [
        "## Preprocessing Step 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXlRXyAzOWex"
      },
      "source": [
        "import gzip\n",
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "from collections import defaultdict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYHCI8wqOWe1"
      },
      "source": [
        "# Extract JSON file\n",
        "def readJSON(path):\n",
        "    for l in gzip.open(path, 'rt'):\n",
        "        d = eval(l)\n",
        "        u = d['userID']\n",
        "        try:\n",
        "            g = d['gameID']\n",
        "        except Exception as e:\n",
        "            g = None\n",
        "        yield u,g,d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB3Eh0zZOWe6"
      },
      "source": [
        "# Extract data as (userId, game id, 1 if played else 0)\n",
        "data = [(u, g, 1) for u, g, _ in readJSON('train.json.gz')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2z5kbdROWe9"
      },
      "source": [
        "# Perform train/val split\n",
        "train_data = data[:165000]\n",
        "val_data = data[165000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WALa0GFxOWfA"
      },
      "source": [
        "## Problem 1: Evaluate performance of baseline model on validation set based on user/item pairs that weren't played"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0uEi2GlOWfA"
      },
      "source": [
        "# Map users to game ids for all data (train and val)\n",
        "u_g_map = defaultdict(list)\n",
        "games_set = set() # Set of unique game ids\n",
        "for u, g, _ in data:\n",
        "    u_g_map[u].append(g)\n",
        "    games_set.add(g)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4NPt97POWfD"
      },
      "source": [
        "# Randomly generate 10k negative entries for each user in val set\n",
        "neg_entries = [] # Keep negative entries for val set in here for now\n",
        "for u, _, _ in val_data:\n",
        "    # Keep sampling a game id for user u until we confirm negative\n",
        "    neg_g = random.sample(games_set, 1)[0]\n",
        "    while neg_g in u_g_map[u]:\n",
        "        neg_g = random.sample(games_set, 1)[0]\n",
        "        \n",
        "    # Add new negative entry\n",
        "    neg_entries.append((u, neg_g, 0))\n",
        "    u_g_map[u].append(neg_g)\n",
        "    \n",
        "# Append negative entries to val data\n",
        "val_data += neg_entries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mynxDYM1OWfF"
      },
      "source": [
        "# Calculate acc between file with predicted labels and expected labels as a list\n",
        "def calc_acc(pred_file, targets):\n",
        "    with open(pred_file, 'r') as f:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for i, l in enumerate(f):\n",
        "            if i == 0:\n",
        "                continue\n",
        "            _, pred = l.split(',')\n",
        "            \n",
        "            correct += int(int(pred) == targets[i-1][2])\n",
        "            total += 1\n",
        "\n",
        "    acc = correct/total\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWj75X61OWfI"
      },
      "source": [
        "# Predict play based on whether game is considered popular\n",
        "def baseline_q1(train_data, val_data):\n",
        "    gameCount = defaultdict(int)\n",
        "    totalPlayed = 0\n",
        "\n",
        "    for i, (user, game, _) in enumerate(train_data):\n",
        "        gameCount[game] += 1\n",
        "        totalPlayed += 1\n",
        "\n",
        "    mostPopular = [(gameCount[x], x) for x in gameCount]\n",
        "    mostPopular.sort()\n",
        "    mostPopular.reverse()\n",
        "\n",
        "    return1 = set()\n",
        "    count = 0\n",
        "    for ic, i in mostPopular:\n",
        "        count += ic\n",
        "        return1.add(i)\n",
        "        if count > totalPlayed/2: break\n",
        "\n",
        "    predictions = open('q1.txt', 'w+')\n",
        "    predictions.write('userID-gameID,prediction\\n')\n",
        "    for l in [u + '-' + g for u, g, _ in val_data]:\n",
        "        if l.startswith(\"userID\"):\n",
        "            #header\n",
        "            predictions.write(l)\n",
        "            continue\n",
        "        u,g = l.strip().split('-')\n",
        "        if g in return1:\n",
        "            predictions.write(u + '-' + g + \",1\\n\")\n",
        "        else:\n",
        "            predictions.write(u + '-' + g + \",0\\n\")\n",
        "\n",
        "    predictions.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtTL-mvkOWfK"
      },
      "source": [
        "# Run baseline predictions on val set\n",
        "baseline_q1(train_data, val_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8ppICKgOWfN",
        "outputId": "20ed2866-d965-454c-d1d6-278513d0ef0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "val_acc = calc_acc('q1.txt', val_data)\n",
        "print(f'Validation accuracy: {val_acc * 100}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy: 68.325%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWjeAoTWOWfQ"
      },
      "source": [
        "The validation accuracy of this baselines can be seen above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGbm0MzLOWfQ"
      },
      "source": [
        "## Problem 2: Find a better threshold for play predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBWEvFZIPsrh"
      },
      "source": [
        "thresh = 1.45 # The threshold I found through manual grid search"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHS-UjCiOWfR"
      },
      "source": [
        "# Redefine play prediction baselines with better threshold\n",
        "# Predict play based on whether game is considered popular\n",
        "\n",
        "def baseline_q2(train_data, val_data):\n",
        "    gameCount = defaultdict(int)\n",
        "    totalPlayed = 0\n",
        "\n",
        "    for i, (user, game, _) in enumerate(train_data):\n",
        "        gameCount[game] += 1\n",
        "        totalPlayed += 1\n",
        "\n",
        "    mostPopular = [(gameCount[x], x) for x in gameCount]\n",
        "    mostPopular.sort()\n",
        "    mostPopular.reverse()\n",
        "\n",
        "    return1 = set()\n",
        "    count = 0\n",
        "    for ic, i in mostPopular:\n",
        "        count += ic\n",
        "        return1.add(i)\n",
        "        if count > totalPlayed/thresh: break\n",
        "\n",
        "    predictions = open('q2.txt', 'w+')\n",
        "    predictions.write('userID-gameID,prediction\\n')\n",
        "    for l in [u + '-' + g for u, g, _ in val_data]:\n",
        "        if l.startswith(\"userID\"):\n",
        "            #header\n",
        "            predictions.write(l)\n",
        "            continue\n",
        "        u,g = l.strip().split('-')\n",
        "        if g in return1:\n",
        "            predictions.write(u + '-' + g + \",1\\n\")\n",
        "        else:\n",
        "            predictions.write(u + '-' + g + \",0\\n\")\n",
        "\n",
        "    predictions.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8S7k8JUOWfT"
      },
      "source": [
        "# Run baseline predictions on val set\n",
        "baseline_q2(train_data, val_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kY_vUZDxOWfV"
      },
      "source": [
        "tmp = np.array(val_data)\n",
        "labels = tmp.T[2]\n",
        "labels = np.array(labels, dtype=np.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYKlb2fTOWfY",
        "outputId": "eaf5009b-d277-4c82-e6b3-edf39279ab1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "val_acc = calc_acc('q2.txt', val_data)\n",
        "print(f'Validation accuracy: {val_acc * 100}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy: 70.26%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnnvVu4cOWfa"
      },
      "source": [
        "I played around with the threshold and found that dividing \"totalPlayed\" by 1.45 yields the highest test accuracy with the above shown. The table shown below shows my grid search.\n",
        "\n",
        "#### Thresh: Val Acc\n",
        "1.4: 69.905% <br>\n",
        "1.45: 70.17999999999999% <br>\n",
        "1.5: 70.13000000000001% <br>\n",
        "1.55: 70.145% <br>\n",
        "1.6: 70.03% <br>\n",
        "1.65: 69.915% <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oGiRtdNOWfb"
      },
      "source": [
        "### Run a sanity check on Q2 (i.e. predict on pairs_Played.txt and submit to Kaggle)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWLXPCRePvuL"
      },
      "source": [
        "thresh = 1.45 # The threshold I found through manual grid search"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv7rVJ8mOWfb"
      },
      "source": [
        "# Run the sanity check for Q2 by predicting on \"pairs_Played.txt\"\n",
        "def sanity_check_q2(train_data, val_data):\n",
        "    gameCount = defaultdict(int)\n",
        "    totalPlayed = 0\n",
        "\n",
        "    for user, game, _ in train_data:\n",
        "        gameCount[game] += 1\n",
        "        totalPlayed += 1\n",
        "\n",
        "    mostPopular = [(gameCount[x], x) for x in gameCount]\n",
        "    mostPopular.sort()\n",
        "    mostPopular.reverse()\n",
        "\n",
        "    return1 = set()\n",
        "    count = 0\n",
        "    for ic, i in mostPopular:\n",
        "        count += ic\n",
        "        return1.add(i)\n",
        "        if count > totalPlayed/thresh: break\n",
        "\n",
        "    predictions = open('sanity_q2.txt', 'w+')\n",
        "    predictions.write('userID-gameID,prediction\\n')\n",
        "    test_data = []\n",
        "    with open('pairs_Played.txt', 'r') as f:\n",
        "        for i, l in enumerate(f):\n",
        "            if i == 0: continue\n",
        "            u, g = l.strip().split('-')\n",
        "            test_data.append((u,g))\n",
        "    for l in [u + '-' + g for u, g in test_data]:\n",
        "        if l.startswith(\"userID\"):\n",
        "            #header\n",
        "            predictions.write(l)\n",
        "            continue\n",
        "        u,g = l.strip().split('-')\n",
        "        if g in return1:\n",
        "            predictions.write(u + '-' + g + \",1\\n\")\n",
        "        else:\n",
        "            predictions.write(u + '-' + g + \",0\\n\")\n",
        "\n",
        "    predictions.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYPy-o9BOWfd"
      },
      "source": [
        "Kaggle accuracy for sanity_q2.txt: 70.300%\n",
        "\n",
        "Note: this is not my answer for Q2, this is just me reporting my result for performing the recommended sanity check as per https://piazza.com/class/kfmxzxpkrfu2db?cid=387. The answer for Q2 is further above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVz0YaTLOWfe"
      },
      "source": [
        "## Problem 3: Stronger baselines using Jaccard similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVu_z_zJOWfe"
      },
      "source": [
        "# Define Jaccard similarity \n",
        "def jaccard_sim(s1, s2):\n",
        "    if type(s1) == list:\n",
        "        s1 = set(s1)\n",
        "    if type(s2) == list:\n",
        "        s2 = set(s2)\n",
        "    num = len(s1.intersection(s2))\n",
        "    den = len(s1.union(s2))\n",
        "    return num / den"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5BA8h7DOWfg"
      },
      "source": [
        "# Calculate max jaccard similarity of g given mapping of users to game ids and game ids to users\n",
        "def max_jaccard(u, g, g_u_map, u_g_map):\n",
        "    max_sim = 0\n",
        "    for g_prime in u_g_map[u]:\n",
        "        if g_prime == g: \n",
        "            continue\n",
        "        # Update max jaccard similarity we've seen so far\n",
        "        max_sim = max(max_sim, jaccard_sim(g_u_map[g], g_u_map[g_prime]))\n",
        "        \n",
        "    return max_sim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A0BOYxmOWfi"
      },
      "source": [
        "# Map users to game ids (for train and val)\n",
        "g_u_map = defaultdict(list)\n",
        "for u, g, _ in train_data:\n",
        "    g_u_map[g].append(u)\n",
        "    \n",
        "# Map game ids to users for all data (train and val)\n",
        "u_g_map = defaultdict(list)\n",
        "for u, g, _ in train_data:\n",
        "    u_g_map[u].append(g)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPB_fMI7OWfp"
      },
      "source": [
        "# For each (u, g, _), predict 'played' if the max of the jaccard similarities between g and g' where g' is game ∈ {user games played}  - {g}\n",
        "def baseline_q3(val_data, thresh):\n",
        "    with open('q3.txt', 'w+') as f:\n",
        "        f.write('userID-gameID,prediction\\n')\n",
        "        for i, (u, g, _) in enumerate(val_data):\n",
        "            max_sim = max_jaccard(u, g, g_u_map, u_g_map)\n",
        "            # Perform prediction based on threshold\n",
        "            f.write(u + '-' + g + ',' + str(int(max_sim > thresh))) # Store the pred\n",
        "            f.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPmoIsRAOWft"
      },
      "source": [
        "# Calculate our predictions for q3\n",
        "jaccard_thresh = 0.04 # Use manually grid searched best thresh\n",
        "baseline_q3(val_data, jaccard_thresh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivvEvZrkOWfw"
      },
      "source": [
        "# Calculate val acc of baseline predictions on val set\n",
        "with open('q3.txt', 'r') as f:\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, l in enumerate(f):\n",
        "        if i == 0:\n",
        "            continue\n",
        "        _, pred = l.strip().split(',')\n",
        "       \n",
        "        correct += int(int(pred) == val_data[i-1][2])\n",
        "        total += 1\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY0-mrDaOWfy",
        "outputId": "0df4280c-0cab-42ec-ef7e-75588bbc4442",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "val_acc = calc_acc('q3.txt', val_data)\n",
        "print(f'Validation accuracy: {correct/total * 100}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy: 64.505%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBpciotGOWf0"
      },
      "source": [
        "## Problem 4: Implement Jaccard-Similarity and Popularity based "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whKW2154QgOg"
      },
      "source": [
        "popularity_thresh = 1.45 # The threshold I found for popularity through manual grid search\n",
        "jaccard_thresh = 0.01 # The threshold I found for jaccard to work best"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbRpl7wqOWf1"
      },
      "source": [
        "def baseline_q4(train_data, val_data, g_u_map, u_g_map, file_name='q4.txt'):\n",
        "\n",
        "    gameCount = defaultdict(int)\n",
        "    totalPlayed = 0\n",
        "\n",
        "    for i, (user, game, _) in enumerate(train_data):\n",
        "        gameCount[game] += 1\n",
        "        totalPlayed += 1\n",
        "\n",
        "    mostPopular = [(gameCount[x], x) for x in gameCount]\n",
        "    mostPopular.sort()\n",
        "    mostPopular.reverse()\n",
        "\n",
        "    return1 = set()\n",
        "    count = 0\n",
        "    for ic, i in mostPopular:\n",
        "        count += ic\n",
        "        return1.add(i)\n",
        "        if count > totalPlayed/popularity_thresh: break\n",
        "\n",
        "    predictions = open(file_name, 'w+')\n",
        "    for l in [u + '-' + g for u, g, _ in val_data]:\n",
        "        if l.startswith(\"userID\"):\n",
        "            #header\n",
        "            predictions.write(l + '\\n')\n",
        "            continue\n",
        "        u,g = l.strip().split('-')\n",
        "        \n",
        "        # Do max jaccard similarity here\n",
        "        max_sim = max_jaccard(u, g, g_u_map, u_g_map)\n",
        "            \n",
        "        if g in return1 and max_sim > jaccard_thresh:\n",
        "            predictions.write(u + '-' + g + \",1\\n\")\n",
        "        else:\n",
        "            predictions.write(u + '-' + g + \",0\\n\")\n",
        "\n",
        "    predictions.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByXA3I-LOWf5"
      },
      "source": [
        "baseline_q4(train_data, val_data, g_u_map, u_g_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSbNlZjOOWf6",
        "outputId": "c745f497-19fa-4ff1-dc47-ebfc861264d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculate validation accuracy for Q4\n",
        "val_acc = calc_acc('q4.txt', val_data)\n",
        "print(f'Validation accuracy: {val_acc * 100}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy: 70.14850742537126%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV0NlIAsQxM4"
      },
      "source": [
        "## Problem 5: Predict on pairs_Played.txt and submit to kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkodWTeeQzD5"
      },
      "source": [
        "# Extract out pairs_Played data\n",
        "pairs_data = []\n",
        "with open('pairs_Played.txt', 'r') as f:\n",
        "    for l in f:\n",
        "        u, g = l.strip().split('-')\n",
        "        pairs_data.append((u, g, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eTmGPaaSSjJ"
      },
      "source": [
        "baseline_q4(train_data, pairs_data, g_u_map, u_g_map, 'q5.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9irwBD2T4Y2"
      },
      "source": [
        "Kaggle username: eyyu12321 <br>\n",
        "Kaggle Accuracy: 70.550%\n",
        "\n",
        "NOTE: on the leaderboards, my name shows up as Eric Yu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgkBiq7gUC9D"
      },
      "source": [
        "## Problem 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQjK37KQWPXu"
      },
      "source": [
        "import gzip\n",
        "import re\n",
        "from sklearn import linear_model\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3Ujr5htW9j4"
      },
      "source": [
        "def parse(f):\n",
        "    for l in gzip.open(f):\n",
        "        yield eval(l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JH465FTcCnL"
      },
      "source": [
        "# Given a string, extract words and remove newlines, punctuation, and upper cases\n",
        "def extract_words(text):\n",
        "    text = text.replace('\\n', ' ') # remove newlines\n",
        "    text = re.sub(r'[^\\w\\s]', '', text) # Remove punctuation\n",
        "    text = text.lower() # Lower case everything\n",
        "    text = [word.strip() for word in text.split(' ')] # Extract every word\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gnch_0IPQ9WA"
      },
      "source": [
        "# Load in category data\n",
        "data = list(parse(\"train_Category.json.gz\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDQ-vG9xWZ1r",
        "outputId": "e8e77291-a755-4313-9285-610317897e8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'date': '2014-02-07',\n",
              " 'early_access': False,\n",
              " 'genre': 'Adventure',\n",
              " 'genreID': 3,\n",
              " 'hours': 4.1,\n",
              " 'reviewID': 'r75487422',\n",
              " 'text': 'Short Review:\\nA good starting chapter for this series, despite the main character being annoying (for now) and a short length. The story is good and actually gets more interesting. Worth the try.\\nLong Review:\\nBlackwell Legacy is the first on the series of (supposedly) 5 games that talks about the main protagonist, Rosangela Blackwell, as being a so called Medium, and in this first chapter we get to know how her story will start and how she will meet her adventure companion Joey...and really, that\\'s really all for for now and that\\'s not a bad thing, because in a way this game wants to show how hard her new job is, and that she cannot escape her destiny as a medium.\\nMy biggest complain for this chapter, except the short length, it\\'s the main protagonist being a \"bit\" too annoying to be likeable, and most of her dialogues will always be about complaining or just be annoyed. Understandable, sure, but lighten\\' up will ya!?\\nHowever, considering that in the next installments she will be much more likeable and kind of interesting, I\\'d say give it a shot and see if you like it: if you hate this first game, you might like the next, or can always stop here.\\nI recommend it.',\n",
              " 'userID': 'u74382925'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4HqNNY1UTLa"
      },
      "source": [
        "# Perform train val split\n",
        "train_data = data[:165000]\n",
        "val_data = data[165000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgRDJRJ0UhAW"
      },
      "source": [
        "# Remove punctuation and capitalization and find 1000 most common words\n",
        "# First, extract all text into single vector\n",
        "text_data = []\n",
        "for datum in train_data:\n",
        "    text = datum['text']\n",
        "    text = extract_words(text)\n",
        "    text_data += text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOmcKHRWUij3"
      },
      "source": [
        "# Count frequencies of each word\n",
        "text_freq_map = Counter(text_data)\n",
        "\n",
        "# Keep track of top 1k words\n",
        "onek_most_common_words = [(word, freq) for freq, word in sorted([(val, key) for key, val in text_freq_map.items()], reverse=True)[:1000]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqJYm-XlZ-jF",
        "outputId": "e3c8d9b8-ad61-47ed-d9bf-6bd377804e7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Report top 10 most common words and frequencies\n",
        "for i, (word, freq) in enumerate(onek_most_common_words[:10]):\n",
        "    print(f'#{i+1} most frequent word: {word}')\n",
        "    print(f'frequency: {freq}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#1 most frequent word: the\n",
            "frequency: 544773\n",
            "#2 most frequent word: and\n",
            "frequency: 317702\n",
            "#3 most frequent word: a\n",
            "frequency: 305503\n",
            "#4 most frequent word: to\n",
            "frequency: 291915\n",
            "#5 most frequent word: game\n",
            "frequency: 245512\n",
            "#6 most frequent word: of\n",
            "frequency: 227426\n",
            "#7 most frequent word: is\n",
            "frequency: 208533\n",
            "#8 most frequent word: you\n",
            "frequency: 200730\n",
            "#9 most frequent word: i\n",
            "frequency: 195982\n",
            "#10 most frequent word: it\n",
            "frequency: 191005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvNPV_V8bX32"
      },
      "source": [
        "## Problem 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a32iCAGWnaGn"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smGU4MmPfjUI"
      },
      "source": [
        "def get_x_y(dataset, most_common_words):\n",
        "    # Create 1k dimensional feature vector representing frequencies of each top 1k words that appear\n",
        "    # in a review\n",
        "    x = np.zeros((len(dataset), len(most_common_words)))\n",
        "    y = np.zeros(len(dataset))\n",
        "\n",
        "    # Create a map indexing each top freq word for mapping to feature vector\n",
        "    word_idx_map = {}\n",
        "    for i, (word, _) in enumerate(most_common_words):\n",
        "        word_idx_map[word] = i\n",
        "    \n",
        "    # Populate X and y\n",
        "    for row, datum in enumerate(dataset):\n",
        "        # populate X first\n",
        "        text = datum['text'] \n",
        "        text = extract_words(text) # extract words\n",
        "        word_freq_map = Counter(text) # Count up frequencies of each unique word in current review text\n",
        "        # Map frequencies to corresponding row and top word index\n",
        "        for word, freq in word_freq_map.items():\n",
        "            idx = word_idx_map.get(word)\n",
        "            if idx == None: \n",
        "                continue\n",
        "            x[row][idx] = freq\n",
        "    \n",
        "        # Now populate y\n",
        "        y[row] = int(datum['genreID'])\n",
        "\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF8TVTRxn9j1"
      },
      "source": [
        "# Loads up a model from pickle\n",
        "def load_model(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        model = pickle.load(f)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xb5weIXeVmL"
      },
      "source": [
        "# Populate train data\n",
        "x_train, y_train = get_x_y(train_data, onek_most_common_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x_2GJ_TfTbc"
      },
      "source": [
        "# Do what we did above, but this time for validation x and y\n",
        "x_val, y_val = get_x_y(val_data, onek_most_common_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZNegbu1epVR"
      },
      "source": [
        "# Build our logistic regressor and perform multinomial classification\n",
        "def log_reg(x, y, x_test, y_test, solver='lbfgs', C=1, max_iter=100, savefile='log_reg_model.pkl'):\n",
        "    # Define log reg model\n",
        "    model = linear_model.LogisticRegression(solver=solver, fit_intercept=True, max_iter=max_iter, C=C)\n",
        "\n",
        "    # Fit model\n",
        "    model.fit(x, y)\n",
        "\n",
        "    # Save our model\n",
        "    with open(savefile, 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "    # Predict on test set passed in, which can also be validation set\n",
        "    preds = model.predict(x_test)\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    preds, y_test = np.array(preds), np.array(y_test)\n",
        "    correct = np.sum((preds == y_test).astype(np.int32))\n",
        "    total = preds.shape[0]\n",
        "    acc = correct / total\n",
        "    return acc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A7eMrfussnl",
        "outputId": "7b1c672f-7213-484e-9015-a1172ac4f348",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(x_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(165000, 1000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeTouSfFhZam",
        "outputId": "8fac743b-63b2-4723-e655-6904552ccc8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculate validation performance\n",
        "# NOTE: we use smaller train size to save time\n",
        "n = 20000\n",
        "val_acc = log_reg(x_train[:n], y_train[:n], x_val, y_val, max_iter=100, savefile='q7_log_reg_model.pkl')\n",
        "print(f'Validation accuracy: {val_acc * 100}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy: 66.42%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yIngDnZKCyQ"
      },
      "source": [
        "#### Validation Accuracy of our model can be seen right above this box."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qbqiO6sjHSW"
      },
      "source": [
        "## Problem 8: Improve performance of classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxnxQOddhiiW"
      },
      "source": [
        "# Increase dictionary size by 500, and include regularization of 0.01\n",
        "\n",
        "# Keep track of top 3000 words\n",
        "q8_most_common_words = [(word, freq) for freq, word in sorted([(val, key) for key, val in text_freq_map.items()], reverse=True)[:2000]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzB_KEaHoTn7"
      },
      "source": [
        "# Populate train data\n",
        "x_train, y_train = get_x_y(train_data, q8_most_common_words)\n",
        "\n",
        "# Do what we did above, but this time for validation x and y\n",
        "x_val, y_val = get_x_y(val_data, q8_most_common_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zVlF4NtlJDk",
        "outputId": "185a11e9-faea-40da-d12e-22950024be62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Initialize c\n",
        "C = 0.1\n",
        "\n",
        "# Train with new regularization constant\n",
        "n = 100000\n",
        "val_acc = log_reg(x_train[:n], y_train[:n], x_val, y_val, max_iter=500, C=C, savefile='q8_log_reg_model.pkl')\n",
        "\n",
        "print(f'Validation accuracy: {val_acc * 100}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy: 69.42%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TG3HU5MRF1O"
      },
      "source": [
        "#### Validation Accuracy of our new model can be seen right above this box. Note that it performs better than Q7 model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKulZJ9k5pTC"
      },
      "source": [
        "def get_x_pairs_category(urs, ur_t_map, most_common_words):\n",
        "    # Create 1k dimensional feature vector representing frequencies of each top 1k words that appear\n",
        "    # in a review\n",
        "    x = np.zeros((len(urs), len(most_common_words)))\n",
        "\n",
        "    # Create a map indexing each top freq word for mapping to feature vector\n",
        "    word_idx_map = {}\n",
        "    for i, (word, _) in enumerate(most_common_words):\n",
        "        word_idx_map[word] = i\n",
        "    \n",
        "    # Populate X and y\n",
        "    for row, (user_id, review_id) in enumerate(urs):\n",
        "        # populate X first\n",
        "        text = ur_t_map[(user_id, review_id)]\n",
        "        word_freq_map = Counter(text) # Count up frequencies of each unique word in current review text\n",
        "        # Map frequencies to corresponding row and top word index\n",
        "        for word, freq in word_freq_map.items():\n",
        "            idx = word_idx_map.get(word)\n",
        "            if idx == None: \n",
        "                continue\n",
        "            x[row][idx] = freq\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSWM1GYHmRCt"
      },
      "source": [
        "def predict_sanity(model, ur_t_map, most_common_words, filename, savefile):\n",
        "    # Predict on pairs_Category to send to kaggle\n",
        "    urs = []\n",
        "    with open(filename, 'r') as f:\n",
        "        for i, l in enumerate(f):\n",
        "            if i == 0: continue\n",
        "            u, r = l.split('-')\n",
        "            u, r = u.strip(), r.strip()\n",
        "            urs.append((u, r))\n",
        "\n",
        "    # Extrapolate x\n",
        "    x = get_x_pairs_category(urs, ur_t_map, most_common_words)\n",
        "\n",
        "    # Compute predicted values\n",
        "    preds = model.predict(x)\n",
        "\n",
        "    # Zip up into file and save\n",
        "    with open(savefile, 'w+') as f:\n",
        "        f.write('userID-reviewID,prediction\\n')\n",
        "        for (u, r), pred in zip(urs, preds):\n",
        "            f.write(u + '-' + r.strip() + ',' + str(int(pred)) + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JleVwjhCEH_"
      },
      "source": [
        "# Load in test category data\n",
        "test_data = list(parse(\"test_Category.json.gz\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DDwViVpyPUO"
      },
      "source": [
        "# Construct a user to text mapping\n",
        "ur_t_map = defaultdict(list)\n",
        "for datum in test_data:\n",
        "    user_id = datum['userID']\n",
        "    review_id = datum['reviewID']\n",
        "    text = extract_words(datum['text'])\n",
        "    ur_t_map[(user_id, review_id)] += text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic8O0HNjqCdH"
      },
      "source": [
        "# Load up our trained model\n",
        "model = load_model('q8_log_reg_model.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8zdPYAVp_7U"
      },
      "source": [
        "# Predict on pairs_Category.txt and it will save into q8.txt. We will then submit q8.txt to kaggle\n",
        "predict_sanity(model, ur_t_map, q8_most_common_words, 'pairs_Category.txt', 'q8.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv7HhCbbD3Zm"
      },
      "source": [
        "### Kaggle Category Score\n",
        "\n",
        "Accuracy: 69.480%"
      ]
    }
  ]
}